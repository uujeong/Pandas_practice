{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35634f5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>Second</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Q</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived  pclass     sex   age  sibsp  parch     fare embarked   class   \n",
       "0           0       3    male  22.0      1      0   7.2500        S   Third  \\\n",
       "1           1       1  female  38.0      1      0  71.2833        C   First   \n",
       "2           1       3  female  26.0      0      0   7.9250        S   Third   \n",
       "3           1       1  female  35.0      1      0  53.1000        S   First   \n",
       "4           0       3    male  35.0      0      0   8.0500        S   Third   \n",
       "..        ...     ...     ...   ...    ...    ...      ...      ...     ...   \n",
       "886         0       2    male  27.0      0      0  13.0000        S  Second   \n",
       "887         1       1  female  19.0      0      0  30.0000        S   First   \n",
       "888         0       3  female   NaN      1      2  23.4500        S   Third   \n",
       "889         1       1    male  26.0      0      0  30.0000        C   First   \n",
       "890         0       3    male  32.0      0      0   7.7500        Q   Third   \n",
       "\n",
       "       who  adult_male deck  embark_town alive  alone  \n",
       "0      man        True  NaN  Southampton    no  False  \n",
       "1    woman       False    C    Cherbourg   yes  False  \n",
       "2    woman       False  NaN  Southampton   yes   True  \n",
       "3    woman       False    C  Southampton   yes  False  \n",
       "4      man        True  NaN  Southampton    no   True  \n",
       "..     ...         ...  ...          ...   ...    ...  \n",
       "886    man        True  NaN  Southampton    no   True  \n",
       "887  woman       False    B  Southampton   yes   True  \n",
       "888  woman       False  NaN  Southampton    no  False  \n",
       "889    man        True    C    Cherbourg   yes   True  \n",
       "890    man        True  NaN   Queenstown    no   True  \n",
       "\n",
       "[891 rows x 15 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "df = sns.load_dataset('titanic')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db9e7cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 15 columns):\n",
      " #   Column       Non-Null Count  Dtype   \n",
      "---  ------       --------------  -----   \n",
      " 0   survived     891 non-null    int64   \n",
      " 1   pclass       891 non-null    int64   \n",
      " 2   sex          891 non-null    object  \n",
      " 3   age          714 non-null    float64 \n",
      " 4   sibsp        891 non-null    int64   \n",
      " 5   parch        891 non-null    int64   \n",
      " 6   fare         891 non-null    float64 \n",
      " 7   embarked     889 non-null    object  \n",
      " 8   class        891 non-null    category\n",
      " 9   who          891 non-null    object  \n",
      " 10  adult_male   891 non-null    bool    \n",
      " 11  deck         203 non-null    category\n",
      " 12  embark_town  889 non-null    object  \n",
      " 13  alive        891 non-null    object  \n",
      " 14  alone        891 non-null    bool    \n",
      "dtypes: bool(2), category(2), float64(2), int64(4), object(5)\n",
      "memory usage: 80.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "161f742c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deck\n",
       "NaN    688\n",
       "C       59\n",
       "B       47\n",
       "D       33\n",
       "E       32\n",
       "A       15\n",
       "F       13\n",
       "G        4\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# deck열에 누락데이터(NaN) 688개 확인\n",
    "# deck 종류별 value 개수 확인 가능\n",
    "\n",
    "nan_deck = df['deck'].value_counts(dropna=False)\n",
    "nan_deck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "476bb7f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass   sex   age  sibsp  parch  fare  embarked  class   who   \n",
       "0      True    True  True  True   True   True  True      True   True  True  \\\n",
       "1      True    True  True  True   True   True  True      True   True  True   \n",
       "2      True    True  True  True   True   True  True      True   True  True   \n",
       "3      True    True  True  True   True   True  True      True   True  True   \n",
       "4      True    True  True  True   True   True  True      True   True  True   \n",
       "\n",
       "   adult_male   deck  embark_town  alive  alone  \n",
       "0        True  False         True   True   True  \n",
       "1        True   True         True   True   True  \n",
       "2        True  False         True   True   True  \n",
       "3        True   True         True   True   True  \n",
       "4        True  False         True   True   True  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 누락데이터를 직접 착는 방법으로 isnull(), notnull()이 있다.\n",
    "## isnull() : 누락 데이터면 True반환, 유효데이터면 False반환\n",
    "## notnull() : 유효데이터면 True반환, 누락데이터면 False반환\n",
    "\n",
    "df.head().notnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1883cc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survived       0\n",
       "pclass         0\n",
       "sex            0\n",
       "age            0\n",
       "sibsp          0\n",
       "parch          0\n",
       "fare           0\n",
       "embarked       0\n",
       "class          0\n",
       "who            0\n",
       "adult_male     0\n",
       "deck           3\n",
       "embark_town    0\n",
       "alive          0\n",
       "alone          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# isnull()의 경우 반환되는 값이 참이면 1, 거짓이면 0으로 판별한다.\n",
    "\n",
    "df.head().isnull().sum(axis=0)  # 참(1)의 합을 구한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec162c4",
   "metadata": {},
   "source": [
    "# 누락 데이터 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46cd6290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "survived ;  0\n",
      "pclass ;  0\n",
      "sex ;  0\n",
      "age ;  177\n",
      "sibsp ;  0\n",
      "parch ;  0\n",
      "fare ;  0\n",
      "embarked ;  2\n",
      "class ;  0\n",
      "who ;  0\n",
      "adult_male ;  0\n",
      "deck ;  688\n",
      "embark_town ;  2\n",
      "alive ;  0\n",
      "alone ;  0\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# titanic 데이터셋 가져오기\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "# for 반복문으로 각 열의 NaN 개수 계산하기\n",
    "missing_df = df.isnull()\n",
    "for col in missing_df.columns:\n",
    "    missing_count = missing_df[col].value_counts()  # 각 열의 NaN 개수 확인\n",
    "    try:\n",
    "        print(col, \"; \", missing_count[True])   # NaN값이 있다면 개수 출력\n",
    "    except:\n",
    "        print(col, \"; \", 0) # NaN 이 없다면 0 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cefb8470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare',\n",
       "       'embarked', 'class', 'who', 'adult_male', 'embark_town', 'alive',\n",
       "       'alone'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NaN 값이 500개 이상인 열을 모두 삭제하여 분석 대상에서 제외한다. (누락 데이터의 차지 비율이 높기 때문)\n",
    "df_thresh = df.dropna(axis=1, thresh=500)\n",
    "df_thresh.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f23d7b3",
   "metadata": {},
   "source": [
    "# 누락 데이터 치환\n",
    "* 일부가 누락되어있더라도 나머지 데이터를 최대한 살려서 데이터 분석에 활용 하는 것이 좋은 결과를 얻는 팁\n",
    "* 누락 데이터를 대체할 값의 예시 : 평균값, 최빈값 - fillna()로 처리 가능\n",
    "* fillna() : 새로운 객체를 반환, 원본 객체를 변경하려면 inplace=True 옵션을 추가해야한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d66961",
   "metadata": {},
   "source": [
    "titanic데이터의 age열 누락데이터 평균값으로 채우기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b11cb492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    22.0\n",
      "1    38.0\n",
      "2    26.0\n",
      "3    35.0\n",
      "4    35.0\n",
      "5     NaN\n",
      "6    54.0\n",
      "7     2.0\n",
      "8    27.0\n",
      "9    14.0\n",
      "Name: age, dtype: float64\n",
      "==========================\n",
      "0    22.000000\n",
      "1    38.000000\n",
      "2    26.000000\n",
      "3    35.000000\n",
      "4    35.000000\n",
      "5    29.699118\n",
      "6    54.000000\n",
      "7     2.000000\n",
      "8    27.000000\n",
      "9    14.000000\n",
      "Name: age, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "# age행 처음 10개 항목 확인 가능\n",
    "print(df['age'].head(10))\n",
    "print(\"==========================\")\n",
    "\n",
    "# age열의 NaN값을 다른 나이 데이터의 평균으로 변경하기\n",
    "mean_age = df['age'].mean(axis=0)   # age열의 평균값(NaN 제외)\n",
    "df['age'].fillna(mean_age, inplace=True)\n",
    "\n",
    "print(df['age'].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2272f2ae",
   "metadata": {},
   "source": [
    "titanic 데이터의 승선 도시를 나타내는 'embark_town'열에 있는 NaN을 다른 값으로 바꾼다.  \n",
    "승객들이 가장 많이 승선한 도시의 이름을 찾아 NaN을 치환한다.  \n",
    "* value_counts() => 승선도시별 승객수 찾기\n",
    "* idxmax() => 가장 큰 값을 갖는 도시(Southampton)을 찾는다.\n",
    "* 결과, 누락 데이터들이 Southampton으로 변경된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c34188b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "825      Q\n",
      "826      S\n",
      "827      C\n",
      "828      Q\n",
      "829    NaN\n",
      "Name: embarked, dtype: object\n",
      "embarked\n",
      "S    644\n",
      "C    168\n",
      "Q     77\n",
      "Name: count, dtype: int64\n",
      "S\n",
      "825    Q\n",
      "826    S\n",
      "827    C\n",
      "828    Q\n",
      "829    S\n",
      "Name: embarked, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "# embarked열의 NaN 출력\n",
    "print(df['embarked'][825:830])\n",
    "\n",
    "# 최빈값 확인하기\n",
    "print(df['embarked'].value_counts())\n",
    "\n",
    "# embarked열의 NaN값을 승선도시 중에서 가장 많이 출현한 값으로 치환하기\n",
    "most_freq = df['embarked'].value_counts(dropna=True).idxmax()\n",
    "print(most_freq)\n",
    "\n",
    "df['embarked'].fillna(most_freq, inplace=True)\n",
    "\n",
    "# 최빈값으로 대체된 것 확인하기\n",
    "print(df['embarked'][825:830])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07834ec",
   "metadata": {},
   "source": [
    "##### 누락데이터가 NaN으로 표시되지 않은 경우\n",
    "* 데이터셋 중에는 누락데이터가 NaN으로 입력되지 않고 0이나 -, ?로 입력되기도 한다.\n",
    "* pandas에서 누락데이터를 다루려면 replace()를 활용하여 numpy에서 지원하는 np.nan으로 변경해주는 것이 좋다.\n",
    "* 예시 : df.replace('?', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38fddf3",
   "metadata": {},
   "source": [
    "### 이웃하고있는 데이터 값으로 치환\n",
    "데이터셋 특성상 서로 이웃하고 있는 데이터끼리 유사성을 가질 가능성이 높다.  \n",
    "앞이나 뒤 값으로 치환해주는 것이 좋다.\n",
    "fillna(method='ffill')옵션 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "94574266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "825      Q\n",
      "826      S\n",
      "827      C\n",
      "828      Q\n",
      "829    NaN\n",
      "Name: embarked, dtype: object\n",
      "825    Q\n",
      "826    S\n",
      "827    C\n",
      "828    Q\n",
      "829    Q\n",
      "Name: embarked, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "df = sns.load_dataset('titanic')\n",
    "# embarked열의 NaN 출력\n",
    "print(df['embarked'][825:830])\n",
    "\n",
    "# NaN값을 인접 데이터로 채워주기\n",
    "df['embarked'].fillna(method='ffill', inplace=True)\n",
    "print(df['embarked'][825:830])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0ae045",
   "metadata": {},
   "source": [
    "# 2. 중복데이터 처리\n",
    "> * **duplicated()** : 각 행의 중복 여부를 나타내는 boolean 시리즈 반환  \n",
    "중복이면 True, 중복이 아니면 False 반환한다.\n",
    "> * **drop_duplicates()** : 중복데이터 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f417b6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  c1  c2  c3\n",
      "0  a   1   1\n",
      "1  a   1   1\n",
      "2  b   1   2\n",
      "3  a   2   2\n",
      "4  b   2   2\n",
      "0    False\n",
      "1     True\n",
      "2    False\n",
      "3    False\n",
      "4    False\n",
      "dtype: bool\n",
      "0    False\n",
      "1     True\n",
      "2     True\n",
      "3    False\n",
      "4     True\n",
      "Name: c2, dtype: bool\n",
      "  c1  c2  c3\n",
      "0  a   1   1\n",
      "2  b   1   2\n",
      "3  a   2   2\n",
      "4  b   2   2\n",
      "  c1  c2  c3\n",
      "0  a   1   1\n",
      "2  b   1   2\n",
      "3  a   2   2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'c1': ['a','a','b','a','b'],\n",
    "    'c2': [1,1,1,2,2],\n",
    "    'c3': [1,1,2,2,2]\n",
    "})\n",
    "\n",
    "print(df)\n",
    "\n",
    "# 데이터프레임 전체 행 데이터 중에서 중복값 찾기\n",
    "df_dup = df.duplicated()\n",
    "print(df_dup)\n",
    "\n",
    "# 특정 열(시리즈)에서 중복값 찾기\n",
    "col_dup = df['c2'].duplicated()\n",
    "print(col_dup)\n",
    "\n",
    "# 중복 데이터 제거  \n",
    "df2 = df.drop_duplicates()\n",
    "print(df2)\n",
    "\n",
    "# 중복데이터 제거 열 속성 기준으로 제거 가능\n",
    "df3 = df.drop_duplicates(subset=['c2','c3'])\n",
    "print(df3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d915aca8",
   "metadata": {},
   "source": [
    "# 3. 데이터 표준화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8465eb1",
   "metadata": {},
   "source": [
    "### 3-1 ) 단위 환산\n",
    "* 마일, 야드, 온스 -> 미터, 평, 그램\n",
    "* 'mpg'데이터 활용\n",
    "* 1마일 == 1.60934km, 1캘런 == 3.78541리터, 1mpg == 0.425km/L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a39f639b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mpg  cylinders  displacement horsepower  weight  acceleration  model year   \n",
      "0  18.0          8         307.0      130.0  3504.0          12.0          70  \\\n",
      "1  15.0          8         350.0      165.0  3693.0          11.5          70   \n",
      "2  18.0          8         318.0      150.0  3436.0          11.0          70   \n",
      "3  16.0          8         304.0      150.0  3433.0          12.0          70   \n",
      "4  17.0          8         302.0      140.0  3449.0          10.5          70   \n",
      "\n",
      "   origin                       name  \n",
      "0       1  chevrolet chevelle malibu  \n",
      "1       1          buick skylark 320  \n",
      "2       1         plymouth satellite  \n",
      "3       1              amc rebel sst  \n",
      "4       1                ford torino  \n",
      "    mpg  cylinders  displacement horsepower  weight  acceleration  model year   \n",
      "0  18.0          8         307.0      130.0  3504.0          12.0          70  \\\n",
      "1  15.0          8         350.0      165.0  3693.0          11.5          70   \n",
      "2  18.0          8         318.0      150.0  3436.0          11.0          70   \n",
      "3  16.0          8         304.0      150.0  3433.0          12.0          70   \n",
      "4  17.0          8         302.0      140.0  3449.0          10.5          70   \n",
      "\n",
      "   origin                       name   kpl  \n",
      "0       1  chevrolet chevelle malibu  7.65  \n",
      "1       1          buick skylark 320  6.38  \n",
      "2       1         plymouth satellite  7.65  \n",
      "3       1              amc rebel sst  6.80  \n",
      "4       1                ford torino  7.22  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 데이터셋 준비\n",
    "df = pd.read_csv('./auto-mpg.csv',header=None)\n",
    "df.columns = ['mpg', 'cylinders', 'displacement','horsepower','weight','acceleration','model year','origin','name']\n",
    "print(df.head())\n",
    "\n",
    "# mpg(mile per gallon)  ->  kpl(kilometer per liter)로 반환\n",
    "# mpg_to_kpl = 0.425\n",
    "mpg_to_kpl = 1.60934/3.78541\n",
    "\n",
    "# mpg * 0.425 결과를 새로운 열(kpl)에 추가\n",
    "df['kpl'] = df['mpg'] * 0.425\n",
    "# kpl열을 소수점 아래 둘째자리에서 반올림\n",
    "df['kpl'] = df['kpl'].round(2)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8120f6eb",
   "metadata": {},
   "source": [
    "### 3-2) 자료형 변환\n",
    "> * 숫자가 문자열(string)일 경우, 숫자형(float or int)로 변환해야한다.\n",
    "> * dtypes 속성을 사용하여 데이터프레임을 구성하는 각 열의 자료형을 확인한다. (df.info()도 사용 가능)\n",
    "> * horsepower(엔진 출력) -> 숫자형\n",
    "> * model year(출시연도), origin(출시국가) -> 범주형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "dcbadbfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mpg             float64\n",
      "cylinders         int64\n",
      "displacement    float64\n",
      "horsepower       object\n",
      "weight          float64\n",
      "acceleration    float64\n",
      "model year        int64\n",
      "origin            int64\n",
      "name             object\n",
      "dtype: object\n",
      "['130.0' '165.0' '150.0' '140.0' '198.0' '220.0' '215.0' '225.0' '190.0'\n",
      " '170.0' '160.0' '95.00' '97.00' '85.00' '88.00' '46.00' '87.00' '90.00'\n",
      " '113.0' '200.0' '210.0' '193.0' '?' '100.0' '105.0' '175.0' '153.0'\n",
      " '180.0' '110.0' '72.00' '86.00' '70.00' '76.00' '65.00' '69.00' '60.00'\n",
      " '80.00' '54.00' '208.0' '155.0' '112.0' '92.00' '145.0' '137.0' '158.0'\n",
      " '167.0' '94.00' '107.0' '230.0' '49.00' '75.00' '91.00' '122.0' '67.00'\n",
      " '83.00' '78.00' '52.00' '61.00' '93.00' '148.0' '129.0' '96.00' '71.00'\n",
      " '98.00' '115.0' '53.00' '81.00' '79.00' '120.0' '152.0' '102.0' '108.0'\n",
      " '68.00' '58.00' '149.0' '89.00' '63.00' '48.00' '66.00' '139.0' '103.0'\n",
      " '125.0' '133.0' '138.0' '135.0' '142.0' '77.00' '62.00' '132.0' '84.00'\n",
      " '64.00' '74.00' '116.0' '82.00']\n",
      "\n",
      "\n",
      "==================horsepower 자료형=====================\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "# transfer horsepower dtypes object to float\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# 데이터셋 준비\n",
    "df = pd.read_csv('./auto-mpg.csv',header=None)\n",
    "df.columns = ['mpg', 'cylinders', 'displacement','horsepower','weight','acceleration','model year','origin','name']\n",
    "print(df.dtypes)  # horsepower 중 문자열 '?'이 포함되어 object로 인식된다.\n",
    "\n",
    "# horsepower 열의 고유값 확인, '?'포함 확인\n",
    "print(df['horsepower'].unique())\n",
    "\n",
    "# 누락데이터 (\"?\") 삭제\n",
    "import numpy as np\n",
    "df['horsepower'].replace('?', np.nan, inplace=True)  # '?' -> np.nan으로 변경\n",
    "df.dropna(subset=['horsepower'], axis=0, inplace=True) # 누락 데이터 행 삭제\n",
    "df['horsepower'] = df['horsepower'].astype('float') # 문자열 -> 실수형\n",
    "\n",
    "# horsepower 열의 자료형 확인\n",
    "print(\"\\n\")\n",
    "print(\"==================horsepower 자료형=====================\")\n",
    "print(df['horsepower'].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5e910006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 3 2]\n",
      "['USA' 'JPN' 'EU']\n",
      "object\n",
      "category\n"
     ]
    }
   ],
   "source": [
    "# transfer origin dtypes int to object\n",
    "print(df['origin'].unique())\n",
    "\n",
    "# 정수형 데이터를 문자형 데이터로 변환\n",
    "df['origin'].replace({\n",
    "    1: 'USA',\n",
    "    2: 'EU',\n",
    "    3: 'JPN'\n",
    "}, inplace=True)\n",
    "\n",
    "# origin열의 고유값과 자료형 확인\n",
    "print(df['origin'].unique())\n",
    "print(df['origin'].dtypes)  # object\n",
    "\n",
    "# origin열은 3개의 국가이름이 반복된다. 고유값이 반복적으로 나타나는 경우 범주형(category)가 효율적이다.\n",
    "# astype('category') 메소드를 사용하면 범주형 데이터로 변환.\n",
    "# 범주형 -> 문자열로 변환하려면 astype('str')메소드를 사용한다.\n",
    "\n",
    "df['origin'] = df['origin'].astype('category')\n",
    "print(df['origin'].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "52a5434c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9      70\n",
      "351    81\n",
      "118    73\n",
      "Name: model year, dtype: int64\n",
      "38     71\n",
      "261    78\n",
      "62     72\n",
      "Name: model year, dtype: category\n",
      "Categories (13, int64): [70, 71, 72, 73, ..., 79, 80, 81, 82]\n"
     ]
    }
   ],
   "source": [
    "# model year열의 정수형 > 범주형으로 변환\n",
    "print(df['model year'].sample(3))\n",
    "df['model year'] = df['model year'].astype('category')\n",
    "print(df['model year'].sample(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f7e7eb",
   "metadata": {},
   "source": [
    "# 4. 범주형(카테고리) 데이터 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b93f180",
   "metadata": {},
   "source": [
    "### 4-1) 구간 분할\n",
    "> * 연속 데이터를 그대로 사용하기보다는 일정한 구간(bin)으로 나누어 분석하는 것이 효율적이다.\n",
    "> * 구간분할(binning) : 연속 변수를 일정한 구간으로 나누고, 각 구간을 범주형 이산 변수로 나누는 과정\n",
    "> * 판다스 cut()를 이용하면 연속 데이터를 여러 구간으로 나누고 범주형 데이터로 변환할 수 있다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5f88df",
   "metadata": {},
   "source": [
    "powerhorse의 output을 숫자로 표시하는 대신 '저출력', '보통출력', '고출력' 등 구간으로 나누어 표시  \n",
    "3개의 구간으로 구분하려면 4개의 경계값이 필요하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5d06bfa3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 46.         107.33333333 168.66666667 230.        ]\n",
      "    horsepower hp_bin\n",
      "0        130.0   보통출력\n",
      "1        165.0   보통출력\n",
      "2        150.0   보통출력\n",
      "3        150.0   보통출력\n",
      "4        140.0   보통출력\n",
      "5        198.0    고출력\n",
      "6        220.0    고출력\n",
      "7        215.0    고출력\n",
      "8        225.0    고출력\n",
      "9        190.0    고출력\n",
      "10       170.0    고출력\n",
      "11       160.0   보통출력\n",
      "12       150.0   보통출력\n",
      "13       225.0    고출력\n",
      "14        95.0    저출력\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('./auto-mpg.csv', header=None)\n",
    "df.columns = ['mpg', 'cylinders', 'displacement','horsepower','weight','acceleration','model year','origin','name']\n",
    "\n",
    "# horsepower의 열데이터 누락('?') 삭제하고 실수형으로 변환\n",
    "df['horsepower'].replace('?', np.nan, inplace=True)\n",
    "df.dropna(subset = ['horsepower'], axis=0, inplace=True)\n",
    "df['horsepower'] = df['horsepower'].astype('float')\n",
    "\n",
    "# np.histogram 함수로 3개의 bin으로 나누는 경계값의 리스트 구하기\n",
    "count, bin_dividers = np.histogram(df['horsepower'], bins=3)  \n",
    "print(bin_dividers) \n",
    "\n",
    "# 3개의 bin에 이름 지정\n",
    "bin_names = ['저출력', '보통출력', '고출력']\n",
    "\n",
    "# pd.cut()로 각 데이터를 3개의 bin에 할당\n",
    "# bin_dividers == 경계값의 리스트, bins옵션에 할당하고 각 구간의 이름(bin_names)을 labels 옵션에 할당한다.\n",
    "df['hp_bin'] = pd.cut(x=df['horsepower'],  # 데이터 배열\n",
    "                     bins=bin_dividers,    # 경계값 리스트\n",
    "                     labels=bin_names,     # bin 이름\n",
    "                     include_lowest=True)  # 첫 경계값 포함\n",
    "\n",
    "# horsepower 열, hp_bin 열의 첫 15행 출력\n",
    "print(df[['horsepower', 'hp_bin']].head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166067d6",
   "metadata": {},
   "source": [
    "### 4-2) 더미 변수\n",
    "> * 범주형 데이터를 회귀분석 등 머신러닝 알고리즘에 바로 사용할 수 없는 경우가 있는데, 컴퓨터가 인식 가능한 입력값으로 변환해야한다.\n",
    "> * 0 또는 1로 표현되는 더미변수를 사용한다.\n",
    "> * 0과 1은 수의 크고 작음이 아니라 feature이 있는지 없는지 여부 표시\n",
    "> * 해당 특성이 있으면 1, 없으면 0 == 원핫벡터 (범주형 데이터를 컴퓨터가 인식할 수 있도록)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "5610ac1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    저출력  보통출력  고출력\n",
      "0     0     1    0\n",
      "1     0     1    0\n",
      "2     0     1    0\n",
      "3     0     1    0\n",
      "4     0     1    0\n",
      "5     0     0    1\n",
      "6     0     0    1\n",
      "7     0     0    1\n",
      "8     0     0    1\n",
      "9     0     0    1\n",
      "10    0     0    1\n",
      "11    0     1    0\n",
      "12    0     1    0\n",
      "13    0     0    1\n",
      "14    1     0    0\n"
     ]
    }
   ],
   "source": [
    "count, bin_dividers = np.histogram(df['horsepower'], bins=3)\n",
    "bin_names = ['저출력', '보통출력', '고출력']\n",
    "\n",
    "# pd.cut()로 각 데이터를 3개의 bin에 할당\n",
    "# bin_dividers == 경계값의 리스트, bins옵션에 할당하고 각 구간의 이름(bin_names)을 labels 옵션에 할당한다.\n",
    "df['hp_bin'] = pd.cut(x=df['horsepower'],  # 데이터 배열\n",
    "                     bins=bin_dividers,    # 경계값 리스트\n",
    "                     labels=bin_names,     # bin 이름\n",
    "                     include_lowest=True)  # 첫 경계값 포함\n",
    "\n",
    "# hp_bin 열의 범주형 데이터를 더미변수로 변환\n",
    "horsepower_dummies = pd.get_dummies(df['hp_bin'], dtype='int')\n",
    "print(horsepower_dummies.head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfaeda2",
   "metadata": {},
   "source": [
    "#### sklearn을 이용해 원핫인코딩을 편리하게 처리할 수 있다.\n",
    "df의 'hp_bin'열에 들어있는 범주형 데이터를 0,1을 원소로 갖는 원핫벳터로 변환한다. -> 결괴 : 희소행렬(sparse matrix)로 변환된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ac54309d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 0 0 0 0 0 0 1 1 0 2]\n",
      "<class 'numpy.ndarray'>\n",
      "[[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [2]]\n",
      "<class 'numpy.ndarray'>\n",
      "  (0, 1)\t1.0\n",
      "  (1, 1)\t1.0\n",
      "  (2, 1)\t1.0\n",
      "  (3, 1)\t1.0\n",
      "  (4, 1)\t1.0\n",
      "  (5, 0)\t1.0\n",
      "  (6, 0)\t1.0\n",
      "  (7, 0)\t1.0\n",
      "  (8, 0)\t1.0\n",
      "  (9, 0)\t1.0\n",
      "  (10, 0)\t1.0\n",
      "  (11, 1)\t1.0\n",
      "  (12, 1)\t1.0\n",
      "  (13, 0)\t1.0\n",
      "  (14, 2)\t1.0\n",
      "<class 'scipy.sparse._csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "# 1차원 벡터를 2차원 벡터로 변환, 다시 희소 행렬로 변환한다.\n",
    "# 희소행렬은 (행, 열) 좌표와 값 형태로 정리된다.\n",
    "# (0,1)은 0행의 1열 위치를 말하고, 데이터 값은 숫자 1,0이 입력된다.\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# 전처리를 위한 encoder 객체 만들기\n",
    "label_encoder = preprocessing.LabelEncoder()   # label encoder 생성\n",
    "onehot_encoder = preprocessing.OneHotEncoder() # one hot encoder 생성\n",
    "\n",
    "# label encoder로 문자열 범주 -> 숫자형 범주로 변환\n",
    "onehot_labeled = label_encoder.fit_transform(df['hp_bin'].head(15))\n",
    "print(onehot_labeled)\n",
    "print(type(onehot_labeled))\n",
    "\n",
    "# 2차원 행렬로 형태 변경\n",
    "onehot_reshaped = onehot_labeled.reshape(len(onehot_labeled), 1)\n",
    "print(onehot_reshaped)\n",
    "print(type(onehot_reshaped))\n",
    "\n",
    "# 희소행렬로 변환\n",
    "onehot_fitted = onehot_encoder.fit_transform(onehot_reshaped)\n",
    "print(onehot_fitted)\n",
    "print(type(onehot_fitted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3771fdca",
   "metadata": {},
   "source": [
    "# 5. 정규화\n",
    "* 각 열의 데이터를 해당 열의 최대값으로 나누면 -> 정규화 결과 최대값은 1이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "eb45e515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    392.000000\n",
      "mean     104.469388\n",
      "std       38.491160\n",
      "min       46.000000\n",
      "25%       75.000000\n",
      "50%       93.500000\n",
      "75%      126.000000\n",
      "max      230.000000\n",
      "Name: horsepower, dtype: float64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋 준비\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('./auto-mpg.csv',header=None)\n",
    "df.columns = ['mpg', 'cylinders', 'displacement','horsepower','weight','acceleration','model year','origin','name']\n",
    "\n",
    "# horsepower열의 누락데이터 '?' 삭제, 실수형으로 변환\n",
    "df['horsepower'].replace('?', np.nan, inplace=True)\n",
    "df.dropna(subset=['horsepower'], inplace=True)\n",
    "df['horsepower'] = df['horsepower'].astype('float')\n",
    "\n",
    "# horsepower 열의 통계 요약 정보로 max 확인\n",
    "print(df.horsepower.describe())\n",
    "print('\\n')\n",
    "\n",
    "# horsepower 열의 최대값의 절대값으로 모든 데이터를 나눠 저장한다.\n",
    "df.horsepower = df.horsepower/abs(df.horsepower.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "ca1d9bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    392.000000\n",
      "mean       0.317768\n",
      "std        0.209191\n",
      "min        0.000000\n",
      "25%        0.157609\n",
      "50%        0.258152\n",
      "75%        0.434783\n",
      "max        1.000000\n",
      "Name: horsepower, dtype: float64\n",
      "\n",
      "\n",
      "0    0.456522\n",
      "1    0.646739\n",
      "2    0.565217\n",
      "3    0.565217\n",
      "4    0.510870\n",
      "Name: horsepower, dtype: float64\n",
      "\n",
      "\n",
      "count    392.000000\n",
      "mean       0.317768\n",
      "std        0.209191\n",
      "min        0.000000\n",
      "25%        0.157609\n",
      "50%        0.258152\n",
      "75%        0.434783\n",
      "max        1.000000\n",
      "Name: horsepower, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 각 열 데이터에서 해당 열의 최소값을 뺀 값을 분자로, 해당 열의 max-min을 분모로 하는 수를 계산하면 가장 큰 값은 역시 1이다.\n",
    "# 'horsepower'열의 최대값은 230, 최소값은 46이다.\n",
    "# max - min 인 184을(230-46) 이용하여 정규화하면 0~1 사이 범위로 변환된다.\n",
    "\n",
    "print(df.horsepower.describe())\n",
    "print('\\n')\n",
    "\n",
    "# horsepower 열의 최대값의 절대값으로 모든 데이터를 나눠서 저장\n",
    "min_x = df.horsepower - df.horsepower.min()\n",
    "min_max = df.horsepower.max() - df.horsepower.min()\n",
    "df.horsepower = min_x / min_max\n",
    "\n",
    "print(df.horsepower.head())\n",
    "print('\\n')\n",
    "print(df.horsepower.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba5b517",
   "metadata": {},
   "source": [
    "# 6. 시계열 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728ef93b",
   "metadata": {},
   "source": [
    "### 6-1) 다른 자료형 -> 시계열 객체로 변환\n",
    "* pandas는 다른 자료형으로 저장된 시간 데이터 -> pandas 시계열 객체인 Timestamp로 변환하는 함수를 제공한다.\n",
    "* **to_datetime()** 함수를 사용하면 문자열 등 다른 자료형을 pandas Timestamp를 나타내는 datetime64로 변환 가능하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acd8b6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Close  Start   High    Low  Volume\n",
      "0  2018-07-02  10100  10850  10900  10000  137977\n",
      "1  2018-06-29  10700  10550  10900   9990  170253\n",
      "2  2018-06-28  10400  10900  10950  10150  155769\n",
      "3  2018-06-27  10900  10800  11050  10500  133548\n",
      "4  2018-06-26  10800  10900  11000  10700   63039\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20 entries, 0 to 19\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Date    20 non-null     object\n",
      " 1   Close   20 non-null     int64 \n",
      " 2   Start   20 non-null     int64 \n",
      " 3   High    20 non-null     int64 \n",
      " 4   Low     20 non-null     int64 \n",
      " 5   Volume  20 non-null     int64 \n",
      "dtypes: int64(5), object(1)\n",
      "memory usage: 1.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 문자열(시리즈 객체)을 판다스 Timestamp로 변환\n",
    "\n",
    "# 데이터 준비하기\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./stock-data.csv')\n",
    "\n",
    "# Date열의 문자열 확인하기\n",
    "print(df.head())\n",
    "print('\\n')\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0564d9fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 20 entries, 2018-07-02 to 2018-06-01\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype         \n",
      "---  ------    --------------  -----         \n",
      " 0   Date      20 non-null     object        \n",
      " 1   Close     20 non-null     int64         \n",
      " 2   Start     20 non-null     int64         \n",
      " 3   High      20 non-null     int64         \n",
      " 4   Low       20 non-null     int64         \n",
      " 5   Volume    20 non-null     int64         \n",
      " 6   new_Date  20 non-null     datetime64[ns]\n",
      "dtypes: datetime64[ns](1), int64(5), object(1)\n",
      "memory usage: 1.8+ KB\n",
      "None\n",
      "\n",
      "\n",
      "====== 새로운 열의 요소 타입 :  <class 'pandas._libs.tslibs.timestamps.Timestamp'> ======\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "      <th>Start</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-07-02</th>\n",
       "      <td>10100</td>\n",
       "      <td>10850</td>\n",
       "      <td>10900</td>\n",
       "      <td>10000</td>\n",
       "      <td>137977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-29</th>\n",
       "      <td>10700</td>\n",
       "      <td>10550</td>\n",
       "      <td>10900</td>\n",
       "      <td>9990</td>\n",
       "      <td>170253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-28</th>\n",
       "      <td>10400</td>\n",
       "      <td>10900</td>\n",
       "      <td>10950</td>\n",
       "      <td>10150</td>\n",
       "      <td>155769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-27</th>\n",
       "      <td>10900</td>\n",
       "      <td>10800</td>\n",
       "      <td>11050</td>\n",
       "      <td>10500</td>\n",
       "      <td>133548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-26</th>\n",
       "      <td>10800</td>\n",
       "      <td>10900</td>\n",
       "      <td>11000</td>\n",
       "      <td>10700</td>\n",
       "      <td>63039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-25</th>\n",
       "      <td>11150</td>\n",
       "      <td>11400</td>\n",
       "      <td>11450</td>\n",
       "      <td>11000</td>\n",
       "      <td>55519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-22</th>\n",
       "      <td>11300</td>\n",
       "      <td>11250</td>\n",
       "      <td>11450</td>\n",
       "      <td>10750</td>\n",
       "      <td>134805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-21</th>\n",
       "      <td>11200</td>\n",
       "      <td>11350</td>\n",
       "      <td>11750</td>\n",
       "      <td>11200</td>\n",
       "      <td>133002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-20</th>\n",
       "      <td>11550</td>\n",
       "      <td>11200</td>\n",
       "      <td>11600</td>\n",
       "      <td>10900</td>\n",
       "      <td>308596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-19</th>\n",
       "      <td>11300</td>\n",
       "      <td>11850</td>\n",
       "      <td>11950</td>\n",
       "      <td>11300</td>\n",
       "      <td>180656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-18</th>\n",
       "      <td>12000</td>\n",
       "      <td>13400</td>\n",
       "      <td>13400</td>\n",
       "      <td>12000</td>\n",
       "      <td>309787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-15</th>\n",
       "      <td>13400</td>\n",
       "      <td>13600</td>\n",
       "      <td>13600</td>\n",
       "      <td>12900</td>\n",
       "      <td>201376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-14</th>\n",
       "      <td>13450</td>\n",
       "      <td>13200</td>\n",
       "      <td>13700</td>\n",
       "      <td>13150</td>\n",
       "      <td>347451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-12</th>\n",
       "      <td>13200</td>\n",
       "      <td>12200</td>\n",
       "      <td>13300</td>\n",
       "      <td>12050</td>\n",
       "      <td>558148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-11</th>\n",
       "      <td>11950</td>\n",
       "      <td>12000</td>\n",
       "      <td>12250</td>\n",
       "      <td>11950</td>\n",
       "      <td>62293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-08</th>\n",
       "      <td>11950</td>\n",
       "      <td>11950</td>\n",
       "      <td>12200</td>\n",
       "      <td>11800</td>\n",
       "      <td>59258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-07</th>\n",
       "      <td>11950</td>\n",
       "      <td>12200</td>\n",
       "      <td>12300</td>\n",
       "      <td>11900</td>\n",
       "      <td>49088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-05</th>\n",
       "      <td>12150</td>\n",
       "      <td>11800</td>\n",
       "      <td>12250</td>\n",
       "      <td>11800</td>\n",
       "      <td>42485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-04</th>\n",
       "      <td>11900</td>\n",
       "      <td>11900</td>\n",
       "      <td>12200</td>\n",
       "      <td>11700</td>\n",
       "      <td>25171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-01</th>\n",
       "      <td>11900</td>\n",
       "      <td>11800</td>\n",
       "      <td>12100</td>\n",
       "      <td>11750</td>\n",
       "      <td>32062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Close  Start   High    Low  Volume\n",
       "new_Date                                      \n",
       "2018-07-02  10100  10850  10900  10000  137977\n",
       "2018-06-29  10700  10550  10900   9990  170253\n",
       "2018-06-28  10400  10900  10950  10150  155769\n",
       "2018-06-27  10900  10800  11050  10500  133548\n",
       "2018-06-26  10800  10900  11000  10700   63039\n",
       "2018-06-25  11150  11400  11450  11000   55519\n",
       "2018-06-22  11300  11250  11450  10750  134805\n",
       "2018-06-21  11200  11350  11750  11200  133002\n",
       "2018-06-20  11550  11200  11600  10900  308596\n",
       "2018-06-19  11300  11850  11950  11300  180656\n",
       "2018-06-18  12000  13400  13400  12000  309787\n",
       "2018-06-15  13400  13600  13600  12900  201376\n",
       "2018-06-14  13450  13200  13700  13150  347451\n",
       "2018-06-12  13200  12200  13300  12050  558148\n",
       "2018-06-11  11950  12000  12250  11950   62293\n",
       "2018-06-08  11950  11950  12200  11800   59258\n",
       "2018-06-07  11950  12200  12300  11900   49088\n",
       "2018-06-05  12150  11800  12250  11800   42485\n",
       "2018-06-04  11900  11900  12200  11700   25171\n",
       "2018-06-01  11900  11800  12100  11750   32062"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new_Date열 추가하기 (열의 각 요소는 timestamp 속성을 가진다.)\n",
    "\n",
    "df['new_Date'] = pd.to_datetime(df['Date'])  # df에 새로운 열 new_Date 추가\n",
    "print(df.info())\n",
    "print('\\n')\n",
    "print(\"====== 새로운 열의 요소 타입 : \",type(df['new_Date'][0]),\"======\")\n",
    "\n",
    "# new_Date열을 df의 행 인덱스로 설정하고, Date열을 제거한다\n",
    "# => 시계열값을 행 인덱스로 지정하면 판다스는 DatetimeIndex로 저장한다.\n",
    "# 시계열 인덱스 클래스를 지원하기 때문에 시간 순서에 맞추어 인덱싱 또는 슬라이싱 하기 편하다.\n",
    "df.set_index('new_Date', inplace=True)\n",
    "df.drop('Date',axis=1,inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "38b1cfeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2019-01-01', '2020-03-01', '2021-06-01'], dtype='datetime64[ns]', freq=None)\n",
      "==== Timestamp  =>  Period ====\n",
      "PeriodIndex(['2019-01-01', '2020-03-01', '2021-06-01'], dtype='period[D]')\n",
      "PeriodIndex(['2019-01', '2020-03', '2021-06'], dtype='period[M]')\n",
      "PeriodIndex(['2019', '2020', '2021'], dtype='period[A-DEC]')\n"
     ]
    }
   ],
   "source": [
    "# Timestamp를 Period로 변환\n",
    "# ( to_period()를 이용하면 일정한 기간을 나타내는 Period객체로 Timestamp객체를 변환할 수 있다. )\n",
    "# ( freq 옵션에 기준이 되는 시간을 설정한다. )\n",
    "import pandas as pd\n",
    "\n",
    "# 날짜 형식의 문자열로 구성되는 리스트 정의\n",
    "dates = ['2019-01-01', '2020-03-01', '2021-06-01']\n",
    "\n",
    "# 문자열의 배열(시리즈 객체)를 판다스 Timestamp로 변환\n",
    "ts_dates = pd.to_datetime(dates)\n",
    "print(ts_dates)\n",
    "\n",
    "# Timestamp를 Period로 변환\n",
    "print('==== Timestamp  =>  Period ====')\n",
    "pr_day = ts_dates.to_period(freq='D')\n",
    "print(pr_day)\n",
    "pr_month = ts_dates.to_period(freq='M')\n",
    "print(pr_month)\n",
    "pr_year = ts_dates.to_period(freq='A')\n",
    "print(pr_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316590d5",
   "metadata": {},
   "source": [
    "### 시계열 데이터의 종류\n",
    "* D : day (1일)\n",
    "* W : week (1주)\n",
    "* M : month end (월말)\n",
    "* MS : month begin (월초)\n",
    "* Q : quarter end (분기말)\n",
    "* QS : quarter begin (분기초)\n",
    "* A : year end (연말)\n",
    "* AS : year begin (연초)\n",
    "* B : business day (휴일 제외)\n",
    "* H : hour (1시간)\n",
    "* T : minute (1분)\n",
    "* S : second (1초)\n",
    "* L : millisecond (1/1,000초)\n",
    "* U : microsecond (1/1,000,000초)\n",
    "* N : nanosecond (1/1,000,000,000초)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fe3a3c",
   "metadata": {},
   "source": [
    "### 6-2) 시계열 데이터 만들기\n",
    "> Timestamp 배열\n",
    "판다스 date_range()를 사용하면 Timestamp(여러개의 날짜)가 들어있는 배열 형태의 시계열 데이터를 만들 수 있다\n",
    "<br> ~= 파이썬 range()로 숫자 배열을 만드는 것과 비슷하다.\n",
    "\n",
    "> Period 배열\n",
    "판다스 period_range()를 사용하면 Period(여러개의 기간)이 들어있는 시계열 데이터를 만들 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a951e3bc",
   "metadata": {},
   "source": [
    "# Timestamp 배열 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "764f8d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2019-01-01 00:00:00+09:00', '2019-02-01 00:00:00+09:00',\n",
      "               '2019-03-01 00:00:00+09:00', '2019-04-01 00:00:00+09:00',\n",
      "               '2019-05-01 00:00:00+09:00', '2019-06-01 00:00:00+09:00'],\n",
      "              dtype='datetime64[ns, Asia/Seoul]', freq='MS')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ts_ms = pd.date_range(start='2019-01-01', # 날짜 범위 시작\n",
    "                     end=None,            # 날짜 범위 끝\n",
    "                     periods=6,           # 생성할 Timestamp 개수\n",
    "                     freq='MS',           # 시간 간격(MS : 월의 시작일)\n",
    "                     tz='Asia/Seoul')     # 시간대(timezone)\n",
    "print(ts_ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f8f9f400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2019-01-31 00:00:00+09:00', '2019-02-28 00:00:00+09:00',\n",
      "               '2019-03-31 00:00:00+09:00', '2019-04-30 00:00:00+09:00',\n",
      "               '2019-05-31 00:00:00+09:00', '2019-06-30 00:00:00+09:00'],\n",
      "              dtype='datetime64[ns, Asia/Seoul]', freq='M')\n",
      "\n",
      "\n",
      "DatetimeIndex(['2019-01-31 00:00:00+09:00', '2019-04-30 00:00:00+09:00',\n",
      "               '2019-07-31 00:00:00+09:00', '2019-10-31 00:00:00+09:00',\n",
      "               '2020-01-31 00:00:00+09:00', '2020-04-30 00:00:00+09:00'],\n",
      "              dtype='datetime64[ns, Asia/Seoul]', freq='3M')\n"
     ]
    }
   ],
   "source": [
    "# freq 옵션을 사용하여 시간 간격 다르게 설정하기\n",
    "\n",
    "# 월 간격, 월의 마지막 날 기준\n",
    "ts_me = pd.date_range('2019-01-01', periods=6,\n",
    "                     freq='M',         # 시간 간격(M: 월의 마지막 날)\n",
    "                     tz='Asia/Seoul')  # 시간대(timezone)\n",
    "print(ts_me)\n",
    "print('\\n')\n",
    "\n",
    "# 분기(3개월)단위, 월의 마지막날 기준\n",
    "ts_3m = pd.date_range(start='2019-01-01', periods=6,\n",
    "                     freq='3M',\n",
    "                     tz='Asia/Seoul')\n",
    "print(ts_3m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548a030a",
   "metadata": {},
   "source": [
    "# Period 배열"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3a73de78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeriodIndex(['2019-01', '2019-02', '2019-03'], dtype='period[M]')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Period 배열 만들기 - 1개월 길이\n",
    "pr_m = pd.period_range(start='2019-01-01', # 날짜 범위 시작\n",
    "                      end=None,            # 날짜 범위 끝\n",
    "                      periods=3,           # 생성할 Period 개수\n",
    "                      freq='M')            # 기간의 길이 (M: 월)\n",
    "print(pr_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "52a0e2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeriodIndex(['2019-01-01 00:00', '2019-01-01 01:00', '2019-01-01 02:00'], dtype='period[H]')\n",
      "\n",
      "\n",
      "PeriodIndex(['2019-01-01 00:00', '2019-01-01 02:00', '2019-01-01 04:00'], dtype='period[2H]')\n"
     ]
    }
   ],
   "source": [
    "# freq 옵션을 활용하여 시간 간격 다르게 하기\n",
    "\n",
    "# 1시간 길이\n",
    "pr_h = pd.period_range(start='2019-01-01',\n",
    "                      end=None,\n",
    "                      periods=3,\n",
    "                      freq='H')\n",
    "print(pr_h)\n",
    "print('\\n')\n",
    "# 2시간 길이\n",
    "pr_2h = pd.period_range(start='2019-01-01',\n",
    "                      end=None,\n",
    "                      periods=3,\n",
    "                      freq='2H')\n",
    "print(pr_2h)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e83a95",
   "metadata": {},
   "source": [
    "### 6-3) 시계열 데이터 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fdede4",
   "metadata": {},
   "source": [
    "# 날짜 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "569a320c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Close  Start   High    Low  Volume   new_Date  Year  Month  Day\n",
      "0  2018-07-02  10100  10850  10900  10000  137977 2018-07-02  2018      7    2\n",
      "1  2018-06-29  10700  10550  10900   9990  170253 2018-06-29  2018      6   29\n",
      "2  2018-06-28  10400  10900  10950  10150  155769 2018-06-28  2018      6   28\n",
      "3  2018-06-27  10900  10800  11050  10500  133548 2018-06-27  2018      6   27\n",
      "4  2018-06-26  10800  10900  11000  10700   63039 2018-06-26  2018      6   26\n",
      "\n",
      "\n",
      "         Date  Close  Start   High    Low  Volume   new_Date  Year  Month   \n",
      "0  2018-07-02  10100  10850  10900  10000  137977 2018-07-02  2018      7  \\\n",
      "1  2018-06-29  10700  10550  10900   9990  170253 2018-06-29  2018      6   \n",
      "2  2018-06-28  10400  10900  10950  10150  155769 2018-06-28  2018      6   \n",
      "3  2018-06-27  10900  10800  11050  10500  133548 2018-06-27  2018      6   \n",
      "4  2018-06-26  10800  10900  11000  10700   63039 2018-06-26  2018      6   \n",
      "\n",
      "   Day Date_yr   Date_m  \n",
      "0    2    2018  2018-07  \n",
      "1   29    2018  2018-06  \n",
      "2   28    2018  2018-06  \n",
      "3   27    2018  2018-06  \n",
      "4   26    2018  2018-06  \n"
     ]
    }
   ],
   "source": [
    "# 데이터 불러오기\n",
    "import pandas as pd\n",
    "df = pd.read_csv('./stock-data.csv')\n",
    "df['new_Date'] = pd.to_datetime(df['Date'])  # 새로운 열 추가\n",
    "\n",
    "# dt 속성을 이용하여 new_Date열의 연-월-일 정보를 년, 월, 일로 구분\n",
    "df['Year'] = df['new_Date'].dt.year\n",
    "df['Month'] = df['new_Date'].dt.month\n",
    "df['Day'] = df['new_Date'].dt.day\n",
    "print(df.head())\n",
    "print('\\n')\n",
    "# Timestamp를 Period로 변환하여 연-월-일 표기 변경하기\n",
    "df['Date_yr'] = df['new_Date'].dt.to_period(freq='A')\n",
    "df['Date_m'] = df['new_Date'].dt.to_period(freq='M')\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "31d082bc",
   "metadata": {},
   "source": [
    "# 날짜 인덱스 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6e685417",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "      <th>Start</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-07-02</th>\n",
       "      <td>2018-07-02</td>\n",
       "      <td>10100</td>\n",
       "      <td>10850</td>\n",
       "      <td>10900</td>\n",
       "      <td>10000</td>\n",
       "      <td>137977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-29</th>\n",
       "      <td>2018-06-29</td>\n",
       "      <td>10700</td>\n",
       "      <td>10550</td>\n",
       "      <td>10900</td>\n",
       "      <td>9990</td>\n",
       "      <td>170253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-28</th>\n",
       "      <td>2018-06-28</td>\n",
       "      <td>10400</td>\n",
       "      <td>10900</td>\n",
       "      <td>10950</td>\n",
       "      <td>10150</td>\n",
       "      <td>155769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-27</th>\n",
       "      <td>2018-06-27</td>\n",
       "      <td>10900</td>\n",
       "      <td>10800</td>\n",
       "      <td>11050</td>\n",
       "      <td>10500</td>\n",
       "      <td>133548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-26</th>\n",
       "      <td>2018-06-26</td>\n",
       "      <td>10800</td>\n",
       "      <td>10900</td>\n",
       "      <td>11000</td>\n",
       "      <td>10700</td>\n",
       "      <td>63039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Date  Close  Start   High    Low  Volume\n",
       "new_Date                                                  \n",
       "2018-07-02  2018-07-02  10100  10850  10900  10000  137977\n",
       "2018-06-29  2018-06-29  10700  10550  10900   9990  170253\n",
       "2018-06-28  2018-06-28  10400  10900  10950  10150  155769\n",
       "2018-06-27  2018-06-27  10900  10800  11050  10500  133548\n",
       "2018-06-26  2018-06-26  10800  10900  11000  10700   63039"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 판다스 Timestamp를 날짜 인덱스로 지정하기\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./stock-data.csv')\n",
    "df['new_Date'] = pd.to_datetime(df['Date'])\n",
    "df.set_index('new_Date', inplace=True)  # 행 인덱스로 지정\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "39a6e185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Date  Close  Start   High    Low  Volume\n",
      "time_delta                                                \n",
      "180 days    2018-06-28  10400  10900  10950  10150  155769\n",
      "181 days    2018-06-27  10900  10800  11050  10500  133548\n",
      "182 days    2018-06-26  10800  10900  11000  10700   63039\n",
      "183 days    2018-06-25  11150  11400  11450  11000   55519\n",
      "186 days    2018-06-22  11300  11250  11450  10750  134805\n",
      "187 days    2018-06-21  11200  11350  11750  11200  133002\n",
      "188 days    2018-06-20  11550  11200  11600  10900  308596\n",
      "189 days    2018-06-19  11300  11850  11950  11300  180656\n"
     ]
    }
   ],
   "source": [
    "# Timestamp 객체로 표시된 두 날짜 사이의 시간 간격을 구할 수 있다.\n",
    "# 시간 간격 계산. 최근 180일 ~ 189일 사이의 값들만 선택하기\n",
    "today = pd.to_datetime('2018-12-25')            # 기준일 생성\n",
    "df['time_delta'] = today - df.index             # 날짜 차이 계산\n",
    "df.set_index('time_delta', inplace=True)        # 행 인덱스로 지정\n",
    "df_180 = df['180 days':'189 days']\n",
    "print(df_180)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
